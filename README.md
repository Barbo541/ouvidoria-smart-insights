##  Tecnologias Utilizadas

- **Linguagem:** Python  
- **Bibliotecas:** Pandas, NumPy, Scikit-learn, SciPy, Matplotlib, NLTK, TextBlob, Streamlit  
- **Ambiente:** VSCode + Virtual Environment (.venv)  
- **Metodologia:** CRISP-DM (Cross Industry Standard Process for Data Mining)  

---

##  Como Executar o Projeto (Windows PowerShell)

```bash
# Criar ambiente virtual
python -m venv .venv

# Instalar dependÃªncias
.\.venv\Scripts\python -m pip install --upgrade pip
.\.venv\Scripts\pip install -r requirements.txt

# Rodar o pipeline ETL e modelo
.\.venv\Scripts\python src\etl_ingest.py
.\.venv\Scripts\python src\etl_transform.py
.\.venv\Scripts\python src\train_classifier.py

# Executar o app Streamlit
.\.venv\Scripts\python -m streamlit run app\Streamlit_demo.py
```

Acesse no navegador:
 http://localhost:8501

 Resultados Obtidos (Base SintÃ©tica)
MÃ©trica	Valor Exemplo
AUC	0.68
Precision	0.00
Recall	0.00
F1-score	0.00
Precision@10%	0.30

 ObservaÃ§Ã£o: Os dados utilizados sÃ£o sintÃ©ticos e tÃªm o propÃ³sito de demonstrar o processo completo de modelagem e deploy.

 PrÃ³ximos Passos
ðŸ”¹ Balancear classes e ajustar limiar de decisÃ£o.

ðŸ”¹ Substituir base sintÃ©tica por dados reais de Ouvidoria.

ðŸ”¹ Adicionar explicabilidade com SHAP ou LIME.

ðŸ”¹ Migrar o pipeline para Databricks Community ou AWS S3.

 Autor
 Marcos Barbosa 
 PÃ³s-graduaÃ§Ã£o em Engenharia de Dados â€“ UNOPAR
 FormaÃ§Ã£o Profissional em CiÃªncia de Dados â€“ EBAC
 Especialista em Engenharia de Dados, MLOps e CiÃªncia de Dados Aplicada a NegÃ³cios
 LinkedIn â€“ barbosa-data
 GitHub â€“ Barbo541






